"""
This type stub file was generated by pyright.
"""

import pandas as pd
import praw
from typing import List, Tuple
from openbb_terminal.common.behavioural_analysis.reddit_helpers import reddit_requirements
from openbb_terminal.decorators import check_api_key, log_start_end

"""Reddit Model."""
__docformat__ = ...
logger = ...
l_sub_reddits = ...
@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_popular_tickers(limit: int = ..., post_limit: int = ..., subreddits: str = ...) -> pd.DataFrame:
    """Get popular tickers from list of subreddits [Source: reddit].

    Parameters
    ----------
    limit : int
        Number of top tickers to get
    post_limit : int
        How many posts to analyze in each subreddit
    subreddits : str, optional
        String of comma separated subreddits.

    Returns
    -------
    pd.DataFrame
        DataFrame of top tickers from supplied subreddits
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_spac_community(limit: int = ..., popular: bool = ...) -> Tuple[pd.DataFrame, dict]:
    """Get top tickers from r/SPACs [Source: reddit].

    Parameters
    ----------
    limit : int
        Number of posts to look at
    popular : bool
        Search by hot instead of new

    Returns
    -------
    Tuple[pd.DataFrame, dict]
        Dataframe of reddit submission,
        Dictionary of tickers and number of mentions.
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_wsb_community(limit: int = ..., new: bool = ...) -> pd.DataFrame:
    """Get wsb posts [Source: reddit].

    Parameters
    ----------
    limit : int, optional
        Number of posts to get, by default 10
    new : bool, optional
        Flag to sort by new instead of hot, by default False

    Returns
    -------
    pd.DataFrame
        Dataframe of reddit submissions
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_due_dilligence(limit: int = ..., n_days: int = ..., show_all_flairs: bool = ...) -> pd.DataFrame:
    """Get due diligence posts from list of subreddits [Source: reddit].

    Parameters
    ----------
    limit: int
        Number of posts to get
    n_days: int
        Number of days back to get posts
    show_all_flairs: bool
        Search through all flairs (apart from Yolo and Meme)

    Returns
    -------
    pd.DataFrame
        Dataframe of submissions
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_posts_about(symbol: str, limit: int = ..., sortby: str = ..., time_frame: str = ..., full_search: bool = ..., subreddits: str = ...) -> Tuple[pd.DataFrame, list, float]:
    """Find posts related to a specific search term in Reddit.

    Parameters
    ----------
    symbol: str
        Ticker symbol to search for
    limit: int
        Number of posts to get per subreddit
    sortby: str
        Search type (Possibilities: "relevance", "hot", "top", "new", or "comments")
    time_frame: str
        Relative time of post (Possibilities: "hour", "day", "week", "month", "year", "all")
    full_search: bool
        Enable comprehensive search for ticker
    subreddits: str
        Comma-separated list of subreddits

    Returns
    -------
    Tuple[pd.DataFrame, list, float]:
        Dataframe of submissions related to the search term,
        List of polarity scores,
        Average polarity score.
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_comments(post: praw.models.reddit.submission.Submission) -> List[praw.models.reddit.comment.Comment]:
    """Recursively gets comments from a post.

    Parameters
    ----------
    post: praw.models.reddit.submission.Submission
        Post to get comments from

    Returns
    -------
    list[praw.models.reddit.comment.Comment]
        List of all comments on the post
    """
    ...

@log_start_end(log=logger)
def clean_reddit_text(docs: List[str]) -> List[str]:
    """Tokenize and clean a list of documents for sentiment analysis.

    Parameters
    ----------
    docs: list[str]
        A list of documents to prepare for sentiment analysis

    Returns
    -------
    list[str]
        List of cleaned and prepared docs
    """
    ...

@log_start_end(log=logger)
@check_api_key(reddit_requirements)
def get_sentiment(post_data: List[str]) -> float:
    """Find the sentiment of a post and related comments.

    Parameters
    ----------
    post_data: list[str]
        A post and its comments in string form

    Returns
    -------
    float
        A number in the range [-1, 1] representing sentiment
    """
    ...

