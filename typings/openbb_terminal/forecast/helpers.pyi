"""
This type stub file was generated by pyright.
"""

import argparse
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, Union
from darts import TimeSeries
from darts.dataprocessing.transformers import Scaler
from darts.models.forecasting.torch_forecasting_model import GlobalForecastingModel
from shap import Explanation
from openbb_terminal import OpenBBFigure
from openbb_terminal.decorators import log_start_end

logger = ...
def mean_absolute_percentage_error(y_true: np.ndarray, y_pred: np.ndarray) -> np.number:
    """Calculate mean absolute percent error"""
    ...

def print_prediction_kpis(real: np.ndarray, pred: np.ndarray): # -> None:
    """Print prediction statistics"""
    ...

def plot_data_predictions(data, preds, y_valid, y_dates_valid, scaler, title, forecast_data, n_loops, time_str: str = ..., external_axes: bool = ...): # -> OpenBBFigure | None:
    """Plots data predictions for the different ML techniques
    external_axes : bool, optional
        Whether to return the figure object or not, by default False
    """
    ...

def prepare_scale_train_valid_test(data: Union[pd.DataFrame, pd.Series], n_input_days: int, n_predict_days: int, test_size: float, s_start_date: Optional[datetime] = ..., s_end_date: Optional[datetime] = ..., no_shuffle: bool = ..., Preprocess: Optional[str] = ...): # -> tuple[Unknown, Literal[True]] | tuple[Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown | list[Unknown], Unknown, Unknown, Unknown | None, Literal[False]]:
    """
    Prepare and scale train, validate and test data. This is an old function for models
    imported from the previous pred menu

    Parameters
    ----------
    data: pd.DataFrame
        Dataframe of stock prices
    ns_parser: argparse.Namespace
        Parsed arguments
    Returns
    -------
    X_train: np.ndarray
        Array of training data.  Shape (# samples, n_inputs, 1)
    X_test: np.ndarray
        Array of validation data.  Shape (total sequences - #samples, n_inputs, 1)
    y_train: np.ndarray
        Array of training outputs.  Shape (#samples, n_days)
    y_test: np.ndarray
        Array of validation outputs.  Shape (total sequences -#samples, n_days)
    X_dates_train: np.ndarray
        Array of dates for X_train
    X_dates_test: np.ndarray
        Array of dates for X_test
    y_dates_train: np.ndarray
        Array of dates for y_train
    y_dates_test: np.ndarray
        Array of dates for y_test
    test_data: np.ndarray
        Array of prices after the specified end date
    dates_test: np.ndarray
        Array of dates after specified end date
    scaler:
        Fitted PREPROCESSOR
    Preprocess: Optional[str]
        The method to preprocess data. Choose: standardization, minmax, normalization, or None.
        Default is standardization.
    """
    ...

def print_pretty_prediction(df_pred: pd.DataFrame, last_price: float): # -> None:
    """Print predictions"""
    ...

def past_covs(past_covariates: Optional[str], data: Union[pd.DataFrame, pd.Series], train_split: float, is_scaler: bool = ...): # -> tuple[Unknown, Unknown, Unknown] | tuple[None, None, None]:
    ...

def early_stopper(patience: int, monitor: str = ...):
    ...

def get_pl_kwargs(patience: int = ..., monitor: str = ..., accelerator: str = ...) -> Dict[str, Any]:
    ...

@log_start_end(log=logger)
def plot_predicted(predicted_values: type[TimeSeries], fig: OpenBBFigure, central_quantile: Union[float, str] = ..., low_quantile: Optional[float] = ..., high_quantile: Optional[float] = ..., label: Optional[Union[str, List[str]]] = ...): # -> OpenBBFigure:
    """Plots the predicted_values time series on the given figure.

    Parameters
    ----------
    predicted_values: TimeSeries
        The predicted values TimeSeries.
    fig: OpenBBFigure
        The figure to plot on.
    central_quantile: float or str
        The quantile (between 0 and 1) to plot as a "central" value, if the series is stochastic (i.e., if
        it has multiple samples). This will be applied on each component separately (i.e., to display quantiles
        of the components' marginal distributions). For instance, setting `central_quantile=0.5` will plot the
        median of each component. `central_quantile` can also be set to 'mean'.
    low_quantile: float
        The quantile to use for the lower bound of the plotted confidence interval. Similar to `central_quantile`,
        this is applied to each component separately (i.e., displaying marginal distributions). No confidence
        interval is shown if `confidence_low_quantile` is None (default 0.05).
    high_quantile: float
        The quantile to use for the upper bound of the plotted confidence interval. Similar to `central_quantile`,
        this is applied to each component separately (i.e., displaying marginal distributions). No confidence
        interval is shown if `high_quantile` is None (default 0.95).
    label: str or list of str
        A prefix that will appear in front of each component of the TimeSeries or a list of string of
        length the number of components in the plotted TimeSeries (default "").
    """
    ...

@log_start_end(log=logger)
def plot_forecast(name: str, target_col: str, historical_fcast: type[TimeSeries], predicted_values: type[TimeSeries], ticker_series: type[TimeSeries], ticker_name: str, data: Union[pd.DataFrame, pd.Series], n_predict: int, forecast_horizon: int, past_covariates: Optional[str] = ..., precision: Optional[int] = ..., probabilistic: bool = ..., export: str = ..., sheet_name: Optional[str] = ..., low_quantile: Optional[float] = ..., high_quantile: Optional[float] = ..., forecast_only: bool = ..., naive: bool = ..., export_pred_raw: bool = ..., metric: str = ..., external_axes: bool = ...) -> Union[None, OpenBBFigure]:
    ...

@log_start_end(log=logger)
def plotly_shap_scatter_plot(shap_values: Explanation, features: Optional[Union[pd.DataFrame, list, np.ndarray]] = ..., feature_names: Optional[Union[List[str], np.ndarray]] = ..., max_display: Optional[int] = ...) -> OpenBBFigure:
    """Generate a shap values summary plot where features are ranked from
    highest mean absolute shap value to lowest, with point clouds shown
    for each feature.

    Parameters:
    -----------
    shap_exp: Explanation
        The shap values for the model.
    features : Optional[Union[pd.DataFrame, list, np.ndarray]]
        Matrix of feature values (# samples x # features) or a feature_names list as shorthand
    feature_names : Optional[List[str]]
        Names of the features (length # features)
    max_display: Optional[int]
        The maximum number of features to display. Defaults to 20.

    Returns:
    --------
    OpenBBFigure
        The shap values summary plot.
    """
    ...

@log_start_end(log=logger)
def plot_explainability(model: type[GlobalForecastingModel], explainability_raw: bool = ..., sheet_name: Optional[str] = ..., export: str = ..., external_axes: bool = ...) -> Union[None, OpenBBFigure]:
    """
    Plot explainability of the model

    Parameters
    ----------
    model: type[GlobalForecastingModel]
        The model to plot explainability for
    explainability_raw: bool
        Whether to plot raw explainability or not
    sheet_name: Optional[str]
        Optionally specify the name of the sheet the data is exported to.
    export: (str, optional)
        Export data to csv, jpg, png, or pdf. Defaults to "".
    external_axes : bool, optional
        Whether to return the figure object or not, by default False
    """
    ...

def dt_format(x) -> str:
    """Convert any Timestamp to YYYY-MM-DD
    Args:
        x: Pandas Timestamp of any length
    Returns:
        x: formatted string
    """
    ...

def get_series(data: pd.DataFrame, target_column: Optional[str] = ..., is_scaler: bool = ..., time_col: str = ...) -> Tuple[Optional[Scaler], TimeSeries]:
    ...

def fit_model(model: type[GlobalForecastingModel], series: TimeSeries, val_series: Optional[TimeSeries] = ..., past_covariates: Optional[TimeSeries] = ..., val_past_covariates: Optional[TimeSeries] = ..., **kwargs): # -> None:
    ...

@log_start_end(log=logger)
def get_prediction(model_name: str, probabilistic: bool, use_scalers: bool, scaler: Optional[Scaler], past_covariates: Optional[str], best_model: type[GlobalForecastingModel], ticker_series: TimeSeries, past_covariate_whole: Optional[TimeSeries], train_split: float, forecast_horizon: int, n_predict: int, metric: str): # -> tuple[Unknown, Unknown, Unknown, Unknown | Unbound, type]:
    ...

def check_parser_input(parser: argparse.ArgumentParser, datasets, *args) -> bool:
    ...

@log_start_end(log=logger)
def plot_residuals(model: type[GlobalForecastingModel], past_covariates: Optional[str], series: Optional[Union[type[TimeSeries], List[type[TimeSeries]], List[np.ndarray]]], forecast_horizon: int = ..., num_bins: int = ..., default_formatting: bool = ...): # -> None:
    ...

def check_data_length(train, test, input_chunk_length: int, output_chunk_length: int) -> bool:
    ...

def filter_dates(data: Union[pd.DataFrame, pd.Series], start_date: Optional[datetime], end_date: Optional[datetime]) -> Union[pd.DataFrame, pd.Series]:
    ...

def clean_data(data: Union[pd.DataFrame, pd.Series], start_date: Optional[datetime] = ..., end_date: Optional[datetime] = ..., target_column: Optional[str] = ..., past_covariates: Optional[str] = ...) -> Union[pd.DataFrame, pd.Series]:
    ...

def clean_covariates(parser, dataset: pd.DataFrame) -> Optional[str]:
    ...

def check_data(data: pd.DataFrame, target_column: str, past_covariates: Optional[str] = ...) -> bool:
    ...

def check_output(output_chunk_length: int, n_predict: int, past_covariates: bool) -> int:
    ...

def check_dates(s: pd.Series) -> bool:
    """Checks whether all hours, minutes, seconds and milliseconds are 0""" ""
    ...

def print_tensorboard_logs(model_save_name: str, user_directory: str): # -> None:
    ...

