"""
This type stub file was generated by pyright.
"""

import pandas as pd
from typing import List, Optional, Tuple, Union
from darts import TimeSeries
from darts.models import TFTModel
from openbb_terminal.decorators import log_start_end

"""Temporal Fusion Transformer Model"""
__docformat__ = ...
logger = ...
@log_start_end(log=logger)
def get_tft_data(data: Union[pd.Series, pd.DataFrame], target_column: str = ..., n_predict: int = ..., past_covariates: Optional[str] = ..., train_split: float = ..., forecast_horizon: int = ..., input_chunk_length: int = ..., output_chunk_length: int = ..., hidden_size: int = ..., lstm_layers: int = ..., num_attention_heads: int = ..., full_attention: bool = ..., dropout: float = ..., hidden_continuous_size: int = ..., n_epochs: int = ..., batch_size: int = ..., model_save_name: str = ..., force_reset: bool = ..., save_checkpoints: bool = ..., metric: str = ...) -> Tuple[Optional[List[TimeSeries]], Optional[List[TimeSeries]], Optional[List[TimeSeries]], Optional[float], Optional[type[TFTModel]],]:
    """Performs Temporal Fusion Transformer forecasting
    The TFT applies multi-head attention queries on future inputs from mandatory future_covariates.
    Specifying future encoders with add_encoders (read below) can automatically generate future
    covariates and allows to use the model without having to pass any future_covariates to fit()
    and predict().

    https://unit8co.github.io/darts/generated_api/darts.models.forecasting.tft_model.html

    Parameters
    ----------
    data (Union[pd.Series, pd.DataFrame]):
        Input Data
    target_column: Optional[str]
        Target column to forecast. Defaults to "close".
    n_predict: (int, optional)
        Days to predict. Defaults to 5.
    train_split: (float, optional)
        Train/val split. Defaults to 0.85.
    past_covariates: (str, optional)
        Multiple secondary columns to factor in when forecasting. Defaults to None.
    forecast_horizon: (int, optional)
        Forecast horizon when performing historical forecasting. Defaults to 5.
    input_chunk_length: (int, optional)
        Number of past time steps that are fed to the forecasting module at prediction time.
        Defaults to 14.
    output_chunk_length: (int, optional)
        The length of the forecast of the model. Defaults to 5.
    hidden_size: (int, optional)
        Hidden state size of the TFT. Defaults to 16.
    lstm_layers: (int, optional)
        Number of layers for the Long Short Term Memory Encoder and Decoder. Defaults to 16.
    num_attention_headers: (int, optional)
        Number of attention heads. Defaults to 4.
    full_attention: (bool, optional)
        Whether to apply a multi-head attention query. Defaults to False>
    dropout: (float, optional)
        Fraction of neurons affected by dropout. Defaults to 0.1.
    hidden_continuous_size: (int, optional)
        Default hidden size for processing continuous variables. Defaults to 8.
    n_epochs: (int, optional)
        Number of epochs to run during training. Defaults to 200.
    batch_size: (int, optional)
        Number of samples to pass through network during a single epoch. Defaults to 32.
    model_save_name: (str, optional)
        The name for the model. Defaults to tft_model
    force_reset: (bool, optional)
        If set to True, any previously-existing model with the same name will be reset
        (all checkpoints will be discarded). Defaults to True.
    save_checkpoints: (bool, optional)
        Whether or not to automatically save the untrained model and checkpoints from training.
        Defaults to True.
    metric: (str, optional)
        Metric to use for model selection. Defaults to "mape".

    Returns
    -------
    Tuple[List[TimeSeries], List[TimeSeries], List[TimeSeries], Optional[float], type[TFTModel]]:
        Adjusted Data series,
        List of historical fcast values,
        List of predicted fcast values,
        Optional[float] - precision,
        Fit Prob. TFT model object.
    """
    ...

